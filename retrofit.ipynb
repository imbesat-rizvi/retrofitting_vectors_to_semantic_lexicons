{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0ed7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 433 µs (2021-06-13T05:28:49/2021-06-13T05:28:49)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b98461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 597 ms (2021-06-13T05:28:50/2021-06-13T05:28:50)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f4be49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 563 µs (2021-06-13T05:28:50/2021-06-13T05:28:50)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # for debugging and testing\n",
    "# embeddings = np.random.randint(low=0, high=10, size=(10,3))\n",
    "# common_idcs = np.array([0,1,5,8])\n",
    "\n",
    "# lex_neigh_to_comm_idcs = [[2,6],\n",
    "#                       [7,8,9],\n",
    "#                       [3],\n",
    "#                       [1,12]]\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b62b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 2.26 ms (2021-06-13T05:28:50/2021-06-13T05:28:50)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_embeddings(filepath, norm=None):\n",
    "    r\"\"\"provide norm='l1' or 'l2' in case vectors are not already normalized\"\"\"\n",
    "    embeddings = []\n",
    "    w2i = dict()\n",
    "    i2w = list()\n",
    "    open_fn = open if not filepath.endswith('.gz') else gzip.open\n",
    "    \n",
    "    with open_fn(filepath, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            \n",
    "            line = line.strip().split()\n",
    "            word = line[0].lower()\n",
    "            w2i[word] = len(i2w)\n",
    "            i2w.append(word)\n",
    "            embeddings.append([float(i) for i in line[1:]])\n",
    "    \n",
    "    embeddings = np.array(embeddings)\n",
    "    if norm:\n",
    "        embeddings = normalize(embeddings, axis=1, norm=norm)\n",
    "    \n",
    "    return w2i, i2w, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7e4329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 1.54 ms (2021-06-13T05:28:51/2021-06-13T05:28:51)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_lexicon(filepath, w2i=None):\n",
    "    lexicon = dict()\n",
    "    \n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            words = line.lower().strip().split()\n",
    "            if words[0].isalpha():\n",
    "                if w2i:\n",
    "                    if words[0] in w2i:\n",
    "                        lexicon[w2i[words[0]]] = [w2i[x] for x in words[1:] \n",
    "                                                 if x.isalpha() and x in w2i]\n",
    "                else:\n",
    "                    lexicon[words[0]] = [w for w in words[1:] if w.isalpha()]\n",
    "                    \n",
    "    # filter word/word_idx with empty neighbours\n",
    "    lexicon = {k:v for k,v in lexicon.items() if v}\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27908bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 661 µs (2021-06-13T05:28:51/2021-06-13T05:28:51)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def indexify_lexicon(w2i, lexicon):\n",
    "    indexed_lexicon = dict()\n",
    "    for word, neighbours in lexicon.items():\n",
    "        if word in w2i:\n",
    "            indexed_lexicon[w2i[word]] = [w2i[x] for x in neighbours\n",
    "                                          if x in w2i]\n",
    "    # filter word/word_idx with empty neighbours\n",
    "    indexed_lexicon = {k:v for k,v in indexed_lexicon.items() if v}\n",
    "    return indexed_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff4acae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 1.85 ms (2021-06-13T05:28:51/2021-06-13T05:28:51)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def retrofit(embeddings, neighbours, n_iter=10):\n",
    "\n",
    "    # append extra row with all 0s as unk token\n",
    "    unk_emb = np.zeros((embeddings.shape[1],))\n",
    "    embeddings = np.vstack((embeddings, unk_emb))\n",
    "    new_embeddings = np.array(embeddings)\n",
    "    \n",
    "    update_idcs, neigh_idcs = [], []\n",
    "    for idx, neigh in neighbours.items():\n",
    "        if idx < len(embeddings)-1:\n",
    "            neigh = [i for i in neigh if i < len(embeddings)-1]\n",
    "            if neigh:\n",
    "                update_idcs.append(idx)\n",
    "                neigh_idcs.append(neigh)\n",
    "    \n",
    "    update_idcs = np.array(update_idcs)\n",
    "    pad_len = max(map(len, neigh_idcs))\n",
    "    neigh_idcs = np.array([arr + [-1]*(pad_len-len(arr)) \n",
    "                           for arr in neigh_idcs])   \n",
    "    neigh_counts = ((neigh_idcs > -1).sum(axis=1)).reshape((-1,1))\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        new_emb = (neigh_counts*embeddings[update_idcs] + \n",
    "                    1*new_embeddings[neigh_idcs].sum(axis=1))\n",
    "        new_emb /= (2*neigh_counts)\n",
    "\n",
    "        new_embeddings[update_idcs,:] = new_emb\n",
    "    \n",
    "    # remove last appended rows with 0s as unk weights\n",
    "    return new_embeddings[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09da0dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 774 µs (2021-06-13T05:28:51/2021-06-13T05:28:51)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2v_filepath = \"sample_vec.txt\"\n",
    "lexicon_filepath = \"framenet.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6726353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 63.8 ms (2021-06-13T05:28:51/2021-06-13T05:28:52)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2i, i2w, embeddings = read_embeddings(w2v_filepath, norm=None)\n",
    "neighbours = read_lexicon(lexicon_filepath, w2i=w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f74daac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>✔️ 4.05 ms (2021-06-13T05:28:52/2021-06-13T05:28:52)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_embeddings = retrofit(embeddings, neighbours, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e77773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
